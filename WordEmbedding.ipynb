{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "regional-logging",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This file is used for some transformations\"\"\"\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "class Toindex(object):\n",
    "    def __init__(self,lookup_table):\n",
    "        assert isinstance(lookup_table,list)\n",
    "        self.lookup_table = lookup_table\n",
    "        \n",
    "    def __call__(self,sample):\n",
    "        X_idx,y_idx = [],[]\n",
    "        X,y = sample[0],sample[1]\n",
    "        for sentence in X:\n",
    "            word_idx = []\n",
    "            for word in sentence:\n",
    "                try:\n",
    "                    word_idx.append(self.lookup_table.index(word))\n",
    "                except:\n",
    "                    word_idx.append(0)\n",
    "            X_idx.append(word_idx)\n",
    "            \n",
    "        for sentence in y:\n",
    "            word_idx = []\n",
    "            for word in sentence:\n",
    "                try:\n",
    "                    word_idx.append(self.lookup_table.index(word))\n",
    "                except:\n",
    "                    word_idx.append(0)\n",
    "            y_idx.append(word_idx)\n",
    "            \n",
    "        return np.array(X_idx),np.array(y_idx)\n",
    "    \n",
    "class ToOnehot(object):\n",
    "    def __init__(self,lookup_table):\n",
    "        assert isinstance(lookup_table,list)\n",
    "        self.lookup_table = lookup_table\n",
    "        \n",
    "    def __call__(self,sample):\n",
    "        vec = []\n",
    "        X,y = sample[0],sample[1]\n",
    "        for sentence in X:\n",
    "            idx_vec = []\n",
    "            for idx in sentence:\n",
    "                zero = np.zeros(len(self.lookup_table))\n",
    "                zero[idx] = 1\n",
    "                idx_vec.append(zero)\n",
    "            vec.append(idx_vec)\n",
    "        return np.asarray(vec),np.asarray(y)\n",
    "    \n",
    "class ToTensor(object):\n",
    "    def __call__(self,samples):\n",
    "        X,y = samples[0],samples[1]\n",
    "        assert isinstance(X,np.ndarray)\n",
    "        X = torch.tensor(X)\n",
    "        y = torch.tensor(y)\n",
    "        return X,y\n",
    "    \n",
    "class CBOW_sum_up(object):\n",
    "    def __call__(self,samples):\n",
    "        X,y = samples[0],samples[1]\n",
    "        return torch.mean(X,1).squeeze(),y\n",
    "        \n",
    "        \n",
    "class Compose(object):\n",
    "    def __init__(self,transforms):\n",
    "        assert isinstance(transforms,list)\n",
    "        self.transforms = transforms\n",
    "    def __call__(self,samples):\n",
    "        for transform in self.transforms:\n",
    "            samples = transform(samples)\n",
    "        return samples\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "sapphire-cliff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This block is used to generate the dataset from the *.csv file\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "\n",
    "class preprocessing():\n",
    "    def __init__(self,vocab_size=250):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.dict = {}\n",
    "        self.vocab = ['UNK']\n",
    "        self.exception = ['.',',','!','?','/','--','']\n",
    "        self.read_csv()\n",
    "        self.build_vocab()\n",
    "    \n",
    "        \n",
    "    def read_csv(self):\n",
    "        df = pd.read_csv('simpsons_dataset.csv')['spoken_words']\n",
    "        self.data = []\n",
    "        for i in range(df.shape[0]):\n",
    "\n",
    "            if type(df[i]) != float:\n",
    "                \n",
    "                self.data.append(self._fliter(df[i]))\n",
    "                \n",
    "        \n",
    "    def _fliter(self,spoken):\n",
    "        spec_char = [',','.','?','!']\n",
    "        for char in spec_char:\n",
    "            spoken = spoken.replace(char,' '+char)\n",
    "        spoken = spoken.lower()\n",
    "        return spoken.split(' ')\n",
    "    \n",
    "    def _build_dict(self,vocab):\n",
    "        if vocab not in self.dict.keys():\n",
    "            self.dict[vocab] = 1\n",
    "        else:\n",
    "            self.dict[vocab]+= 1\n",
    "            \n",
    "    def build_vocab(self):\n",
    "        for sentence in self.data:\n",
    "            for vocab in sentence:\n",
    "                self._build_dict(vocab)\n",
    "                \n",
    "        freq_vocab = sorted(list(self.dict.items()),key = lambda x: x[1],reverse=True)\n",
    "        count = 0\n",
    "        for vocab in freq_vocab:\n",
    "            if vocab[0] not in self.exception:\n",
    "                self.vocab.append(vocab[0])\n",
    "                count += 1\n",
    "        self.vocab = self.vocab[:self.vocab_size+1]\n",
    "        \n",
    "        \n",
    "class CBOW_Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,preprocessing,window_size=1,transform=None):\n",
    "        assert isinstance(preprocessing, object)\n",
    "        self.window_size = window_size\n",
    "        self.data = preprocessing.data\n",
    "        self.freq = preprocessing.dict\n",
    "        self.vocab = preprocessing.vocab\n",
    "        self.transform = transform\n",
    "        self.Generate()\n",
    "        \n",
    "        \n",
    "    def select(self,sentence):\n",
    "        train_data = []\n",
    "        for target in sentence:\n",
    "            count = 0\n",
    "            if target in self.vocab:\n",
    "                idx = sentence.index(target)\n",
    "                if idx >= self.window_size and idx+self.window_size+1<=len(sentence):\n",
    "                    X1 = sentence[idx-self.window_size:idx]\n",
    "                    X2 = sentence[idx+1:idx+self.window_size+1]\n",
    "                    X1.extend(X2)\n",
    "                    count = sum(list(map(lambda x: 1 if x not in self.vocab else 0,X1)))\n",
    "                    if count < self.window_size:\n",
    "                        X1.append(target)\n",
    "                        train_data.append(X1)\n",
    "        return train_data\n",
    "                \n",
    "    def Generate(self):\n",
    "        self.traindata = []\n",
    "        for sentence in self.data:\n",
    "                self.traindata.extend(self.select(sentence))\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.traindata)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if torch.is_tensor(index):\n",
    "            index = index.to_list()\n",
    "            \n",
    "        data = self.traindata[index]            \n",
    "        samples = [data[:-1]],[[data[-1]]]\n",
    "        \n",
    "        if self.transform:\n",
    "            samples = self.transform(samples)\n",
    "        \n",
    "        return samples\n",
    "    \n",
    "    \n",
    "class Skip_Gram_Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,preprocessing,window_size=1,transform=None):\n",
    "        assert isinstance(preprocessing, object)\n",
    "        self.window_size = window_size\n",
    "        self.data = preprocessing.data\n",
    "        self.freq = preprocessing.dict\n",
    "        self.vocab = preprocessing.vocab\n",
    "        self.transform = transform\n",
    "        self.Generate()\n",
    "        \n",
    "        \n",
    "    def select(self,sentence):\n",
    "        train_data = []\n",
    "        for target in sentence:\n",
    "            count = 0\n",
    "            if target in self.vocab:\n",
    "                idx = sentence.index(target)\n",
    "                if idx >= self.window_size and idx+self.window_size+1<=len(sentence):\n",
    "                    X1 = sentence[idx-self.window_size:idx]\n",
    "                    X2 = sentence[idx+1:idx+self.window_size+1]\n",
    "                    X1.extend(X2)\n",
    "                    for cnt_word in X1:\n",
    "                        if cnt_word in self.vocab:\n",
    "                            train_data.append([target,cnt_word])\n",
    "                            \n",
    "        return train_data\n",
    "                \n",
    "    def Generate(self):\n",
    "        self.traindata = []\n",
    "        for sentence in self.data:\n",
    "                self.traindata.extend(self.select(sentence))\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.traindata)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if torch.is_tensor(index):\n",
    "            index = index.to_list()\n",
    "            \n",
    "        data = self.traindata[index]            \n",
    "        samples = [[data[0]]],[[data[-1]]]\n",
    "        \n",
    "        if self.transform:\n",
    "            samples = self.transform(samples)\n",
    "        \n",
    "        return samples\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "rolled-gravity",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Here is the definition of the model\"\"\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Embedding(nn.Module):\n",
    "    def __init__(self,v_dim,hidden_size):\n",
    "        super(Embedding,self).__init__()\n",
    "        self.fc1 = nn.Linear(v_dim, hidden_size,bias=False)\n",
    "        self.out = nn.Linear(hidden_size, v_dim)\n",
    "        self.act = nn.Softmax()\n",
    "    def forward(self,x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.out(x)\n",
    "        out = self.act(x)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "basic-state",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HomePC\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [1/6] Loss: 5.8612\n",
      "Epoch [1/5], Step [2/6] Loss: 5.8567\n",
      "Epoch [1/5], Step [3/6] Loss: 5.7258\n",
      "Epoch [1/5], Step [4/6] Loss: 5.6802\n",
      "Epoch [1/5], Step [5/6] Loss: 5.6615\n",
      "Epoch [1/5], Step [6/6] Loss: 5.6496\n",
      "Epoch [2/5], Step [1/6] Loss: 5.6506\n",
      "Epoch [2/5], Step [2/6] Loss: 5.6495\n",
      "Epoch [2/5], Step [3/6] Loss: 5.6464\n",
      "Epoch [2/5], Step [4/6] Loss: 5.6414\n",
      "Epoch [2/5], Step [5/6] Loss: 5.6328\n",
      "Epoch [2/5], Step [6/6] Loss: 5.6221\n",
      "Epoch [3/5], Step [1/6] Loss: 5.6340\n",
      "Epoch [3/5], Step [2/6] Loss: 5.6315\n",
      "Epoch [3/5], Step [3/6] Loss: 5.6319\n",
      "Epoch [3/5], Step [4/6] Loss: 5.6319\n",
      "Epoch [3/5], Step [5/6] Loss: 5.6308\n",
      "Epoch [3/5], Step [6/6] Loss: 5.6434\n",
      "Epoch [4/5], Step [1/6] Loss: 5.6324\n",
      "Epoch [4/5], Step [2/6] Loss: 5.6312\n",
      "Epoch [4/5], Step [3/6] Loss: 5.6294\n",
      "Epoch [4/5], Step [4/6] Loss: 5.6309\n",
      "Epoch [4/5], Step [5/6] Loss: 5.6299\n",
      "Epoch [4/5], Step [6/6] Loss: 5.6246\n",
      "Epoch [5/5], Step [1/6] Loss: 5.6283\n",
      "Epoch [5/5], Step [2/6] Loss: 5.6279\n",
      "Epoch [5/5], Step [3/6] Loss: 5.6283\n",
      "Epoch [5/5], Step [4/6] Loss: 5.6294\n",
      "Epoch [5/5], Step [5/6] Loss: 5.6291\n",
      "Epoch [5/5], Step [6/6] Loss: 5.6072\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "vocab_parser = Dataset.preprocessing(vocab_size=350)\n",
    "\n",
    "dataset = CBOW_Dataset(vocab_parser,\n",
    "                       window_size=1,\n",
    "                       transform=Compose([Toindex(vocab_parser.vocab),\n",
    "                                          ToOnehot(vocab_parser.vocab),\n",
    "                                          ToTensor(),\n",
    "                                          CBOW_sum_up()]))\n",
    "\n",
    "train_loader = DataLoader(dataset,batch_size=50000,shuffle=True)\n",
    "\n",
    "model = Embedding(351,128)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-1)\n",
    "\n",
    "num_epochs = 5\n",
    "total_step = len(train_loader)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (X,y) in enumerate(train_loader):\n",
    "        X = X.type(torch.FloatTensor)\n",
    "        y = y.type(torch.LongTensor).squeeze()\n",
    "        \n",
    "        outputs = model(X)\n",
    "        loss = criterion(outputs,y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "        print (\"Epoch [{}/{}], Step [{}/{}] Loss: {:.4f}\"\n",
    "                .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "\n",
    "# torch.save(model.state_dict(),'CBOW.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "personal-habitat",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HomePC\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [1/20] Loss: 5.8664\n",
      "Epoch [1/5], Step [2/20] Loss: 5.8566\n",
      "Epoch [1/5], Step [3/20] Loss: 5.8028\n",
      "Epoch [1/5], Step [4/20] Loss: 5.7847\n",
      "Epoch [1/5], Step [5/20] Loss: 5.7812\n",
      "Epoch [1/5], Step [6/20] Loss: 5.7806\n",
      "Epoch [1/5], Step [7/20] Loss: 5.7797\n",
      "Epoch [1/5], Step [8/20] Loss: 5.7814\n",
      "Epoch [1/5], Step [9/20] Loss: 5.7797\n",
      "Epoch [1/5], Step [10/20] Loss: 5.7806\n",
      "Epoch [1/5], Step [11/20] Loss: 5.7791\n",
      "Epoch [1/5], Step [12/20] Loss: 5.7812\n",
      "Epoch [1/5], Step [13/20] Loss: 5.7804\n",
      "Epoch [1/5], Step [14/20] Loss: 5.7787\n",
      "Epoch [1/5], Step [15/20] Loss: 5.7811\n",
      "Epoch [1/5], Step [16/20] Loss: 5.7807\n",
      "Epoch [1/5], Step [17/20] Loss: 5.7795\n",
      "Epoch [1/5], Step [18/20] Loss: 5.7797\n",
      "Epoch [1/5], Step [19/20] Loss: 5.7802\n",
      "Epoch [1/5], Step [20/20] Loss: 5.7778\n",
      "Epoch [2/5], Step [1/20] Loss: 5.7804\n",
      "Epoch [2/5], Step [2/20] Loss: 5.7784\n",
      "Epoch [2/5], Step [3/20] Loss: 5.7784\n",
      "Epoch [2/5], Step [4/20] Loss: 5.7807\n",
      "Epoch [2/5], Step [5/20] Loss: 5.7814\n",
      "Epoch [2/5], Step [6/20] Loss: 5.7806\n",
      "Epoch [2/5], Step [7/20] Loss: 5.7804\n",
      "Epoch [2/5], Step [8/20] Loss: 5.7790\n",
      "Epoch [2/5], Step [9/20] Loss: 5.7811\n",
      "Epoch [2/5], Step [10/20] Loss: 5.7810\n",
      "Epoch [2/5], Step [11/20] Loss: 5.7792\n",
      "Epoch [2/5], Step [12/20] Loss: 5.7790\n",
      "Epoch [2/5], Step [13/20] Loss: 5.7800\n",
      "Epoch [2/5], Step [14/20] Loss: 5.7799\n",
      "Epoch [2/5], Step [15/20] Loss: 5.7803\n",
      "Epoch [2/5], Step [16/20] Loss: 5.7804\n",
      "Epoch [2/5], Step [17/20] Loss: 5.7808\n",
      "Epoch [2/5], Step [18/20] Loss: 5.7791\n",
      "Epoch [2/5], Step [19/20] Loss: 5.7795\n",
      "Epoch [2/5], Step [20/20] Loss: 5.7826\n",
      "Epoch [3/5], Step [1/20] Loss: 5.7798\n",
      "Epoch [3/5], Step [2/20] Loss: 5.7786\n",
      "Epoch [3/5], Step [3/20] Loss: 5.7807\n",
      "Epoch [3/5], Step [4/20] Loss: 5.7807\n",
      "Epoch [3/5], Step [5/20] Loss: 5.7806\n",
      "Epoch [3/5], Step [6/20] Loss: 5.7800\n",
      "Epoch [3/5], Step [7/20] Loss: 5.7788\n",
      "Epoch [3/5], Step [8/20] Loss: 5.7788\n",
      "Epoch [3/5], Step [9/20] Loss: 5.7804\n",
      "Epoch [3/5], Step [10/20] Loss: 5.7794\n",
      "Epoch [3/5], Step [11/20] Loss: 5.7790\n",
      "Epoch [3/5], Step [12/20] Loss: 5.7799\n",
      "Epoch [3/5], Step [13/20] Loss: 5.7811\n",
      "Epoch [3/5], Step [14/20] Loss: 5.7796\n",
      "Epoch [3/5], Step [15/20] Loss: 5.7792\n",
      "Epoch [3/5], Step [16/20] Loss: 5.7785\n",
      "Epoch [3/5], Step [17/20] Loss: 5.7794\n",
      "Epoch [3/5], Step [18/20] Loss: 5.7792\n",
      "Epoch [3/5], Step [19/20] Loss: 5.7802\n",
      "Epoch [3/5], Step [20/20] Loss: 5.7780\n",
      "Epoch [4/5], Step [1/20] Loss: 5.7840\n",
      "Epoch [4/5], Step [2/20] Loss: 5.7791\n",
      "Epoch [4/5], Step [3/20] Loss: 5.7793\n",
      "Epoch [4/5], Step [4/20] Loss: 5.7811\n",
      "Epoch [4/5], Step [5/20] Loss: 5.7817\n",
      "Epoch [4/5], Step [6/20] Loss: 5.7798\n",
      "Epoch [4/5], Step [7/20] Loss: 5.7809\n",
      "Epoch [4/5], Step [8/20] Loss: 5.7809\n",
      "Epoch [4/5], Step [9/20] Loss: 5.7804\n",
      "Epoch [4/5], Step [10/20] Loss: 5.7782\n",
      "Epoch [4/5], Step [11/20] Loss: 5.7808\n",
      "Epoch [4/5], Step [12/20] Loss: 5.7783\n",
      "Epoch [4/5], Step [13/20] Loss: 5.7781\n",
      "Epoch [4/5], Step [14/20] Loss: 5.7796\n",
      "Epoch [4/5], Step [15/20] Loss: 5.7769\n",
      "Epoch [4/5], Step [16/20] Loss: 5.7784\n",
      "Epoch [4/5], Step [17/20] Loss: 5.7780\n",
      "Epoch [4/5], Step [18/20] Loss: 5.7790\n",
      "Epoch [4/5], Step [19/20] Loss: 5.7805\n",
      "Epoch [4/5], Step [20/20] Loss: 5.7784\n",
      "Epoch [5/5], Step [1/20] Loss: 5.7785\n",
      "Epoch [5/5], Step [2/20] Loss: 5.7783\n",
      "Epoch [5/5], Step [3/20] Loss: 5.7806\n",
      "Epoch [5/5], Step [4/20] Loss: 5.7815\n",
      "Epoch [5/5], Step [5/20] Loss: 5.7801\n",
      "Epoch [5/5], Step [6/20] Loss: 5.7807\n",
      "Epoch [5/5], Step [7/20] Loss: 5.7801\n",
      "Epoch [5/5], Step [8/20] Loss: 5.7780\n",
      "Epoch [5/5], Step [9/20] Loss: 5.7806\n",
      "Epoch [5/5], Step [10/20] Loss: 5.7793\n",
      "Epoch [5/5], Step [11/20] Loss: 5.7787\n",
      "Epoch [5/5], Step [12/20] Loss: 5.7794\n",
      "Epoch [5/5], Step [13/20] Loss: 5.7784\n",
      "Epoch [5/5], Step [14/20] Loss: 5.7783\n",
      "Epoch [5/5], Step [15/20] Loss: 5.7783\n",
      "Epoch [5/5], Step [16/20] Loss: 5.7794\n",
      "Epoch [5/5], Step [17/20] Loss: 5.7800\n",
      "Epoch [5/5], Step [18/20] Loss: 5.7804\n",
      "Epoch [5/5], Step [19/20] Loss: 5.7802\n",
      "Epoch [5/5], Step [20/20] Loss: 5.7814\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "vocab_parser = Dataset.preprocessing(vocab_size=350)\n",
    "\n",
    "dataset = Skip_Gram_Dataset(vocab_parser,\n",
    "                            window_size=2,\n",
    "                            transform=Compose([Toindex(vocab_parser.vocab),\n",
    "                                               ToOnehot(vocab_parser.vocab),\n",
    "                                               ToTensor()]))\n",
    "\n",
    "train_loader = DataLoader(dataset,batch_size=80000,shuffle=True)\n",
    "\n",
    "model = Embedding(351,128)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-1)\n",
    "\n",
    "num_epochs = 5\n",
    "total_step = len(train_loader)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (X,y) in enumerate(train_loader):\n",
    "        X = X.type(torch.FloatTensor).squeeze()\n",
    "        y = y.type(torch.LongTensor).squeeze()\n",
    "        # print(X.shape)\n",
    "        # Forward pass\n",
    "        outputs = model(X)\n",
    "        # print(outputs.shape)\n",
    "        loss = criterion(outputs,y)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "        print (\"Epoch [{}/{}], Step [{}/{}] Loss: {:.4f}\"\n",
    "                .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "\n",
    "#torch.save(model.state_dict(),'Skip_Gram.pt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "embedded-correspondence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding trained by CBOW\n",
      "Keyword is  homer\n",
      "The most relevant vocabulary:\n",
      "lisa\n",
      "moe\n",
      "bart\n",
      ",\"\n",
      "marge\n",
      "wow\n",
      "milhouse\n",
      "huh\n",
      "UNK\n",
      "whoa\n",
      "maggie\n",
      "ow\n",
      "dad\n",
      "c'mon\n",
      "mother\n",
      "me\n",
      "burns\n",
      "sir\n",
      "flanders\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "v_dim = 350\n",
    "vocab_parser = Dataset.preprocessing(v_dim)\n",
    "\n",
    "model = Embedding(v_dim+1,128)\n",
    "model.load_state_dict(torch.load('CBOW.pt'))\n",
    "\n",
    "\n",
    "vocab = vocab_parser.vocab\n",
    "print(\"Embedding trained by CBOW\")\n",
    "\n",
    "test = 'homer'\n",
    "print(\"Keyword is \",test)\n",
    "index = vocab.index(test)\n",
    "\n",
    "embedding = list(model.fc1.parameters())[0].t()\n",
    "\n",
    "word = embedding[index]\n",
    "dis = []\n",
    "for i in embedding:\n",
    "    dis.append(torch.sqrt(torch.sum((word-i)**2)))\n",
    "dis = np.argsort(dis)[1:20]\n",
    "print(\"The most relevant vocabulary:\")\n",
    "\n",
    "for i in dis:\n",
    "    print(vocab[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "textile-walnut",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding trained by Skip_Gram\n",
      "Keyword is  homer\n",
      "The most relevant vocabulary:\n",
      "mom\n",
      "honey\n",
      "marge\n",
      "three\n",
      ",\"\n",
      "maggie\n",
      "they\n",
      "'em\n",
      "every\n",
      "moe\n",
      "everything\n",
      "two\n",
      "cool\n",
      "again\n",
      "hear\n",
      "that\n",
      "okay\n",
      "remember\n",
      "sure\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "v_dim = 350\n",
    "vocab_parser = Dataset.preprocessing(v_dim)\n",
    "\n",
    "model = Embedding(v_dim+1,128)\n",
    "model.load_state_dict(torch.load('Skip_Gram.pt'))\n",
    "\n",
    "\n",
    "vocab = vocab_parser.vocab\n",
    "\n",
    "print(\"Embedding trained by Skip_Gram\")\n",
    "test = 'homer'\n",
    "print(\"Keyword is \",test)\n",
    "index = vocab.index(test)\n",
    "\n",
    "embedding = list(model.fc1.parameters())[0].t()\n",
    "\n",
    "word = embedding[index]\n",
    "dis = []\n",
    "for i in embedding:\n",
    "    dis.append(torch.sqrt(torch.sum((word-i)**2)))\n",
    "dis = np.argsort(dis)[1:20]\n",
    "print(\"The most relevant vocabulary:\")\n",
    "\n",
    "for i in dis:\n",
    "    print(vocab[i])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rental-witness",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unauthorized-mustang",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
